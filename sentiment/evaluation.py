# -*- coding: utf-8 -*-
"""Evaluation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1z7TffQwKtZt5TEx0oJ2l4ypHszEs_aqh
"""

import ssl
import nltk
import certifi
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import pandas as pd
import matplotlib.pyplot as plt
import re
import numpy as np

from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

# Load the pre-trained model and tokenizer
model_name = "cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Create a sentiment-analysis pipeline
sentiment_analyzer = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

sentiment_analyzer('Ursula')

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

conversations = pd.read_csv("final_test_all.csv")
conversations.head(10)

# Configure SSL context to use certifis CA bundle
ssl_context = ssl.create_default_context(cafile=certifi.where())
ssl._create_default_https_context = lambda: ssl_context

# Download the vader_lexicon data
nltk.download('vader_lexicon')

analyser = SentimentIntensityAnalyzer()

# Data Cleaning (only remove URLs)
# Overrides the existing column "cleaned_text"

# Function to clean tweet text without removing special characters
def clean_tweet_text(text):
    # Remove URLs
    text = str(text)
    text = re.sub(r"http\S+|www\S+|https\S+", '', text, flags=re.MULTILINE)
    return text

# Apply cleaning function to the text column
conversations['clean_text'] = conversations['text'].apply(clean_tweet_text)

# conversations = conversations.drop(conversations[conversations.sentiment == "Irrelevant"].index)

conversations.head(10)

conversations['compound'] = [analyser.polarity_scores(x)['compound'] for x in conversations['clean_text']]

conversations.head(10)

# Function to categorize sentiment based on score
def categorize_sentiment(row):
    score = row["compound"]

    if score > 0.05:
        return "positive"
    elif score < -0.05:
        return "negative"
    else:
        return "neutral"

# # Apply categorization function to the sentiment score column
conversations['vader'] = conversations.apply(categorize_sentiment, axis=1)

def is_equal(row):
    sentiment = row["actual_sent"]
    vader = row["vader"]

    if vader == sentiment:
        return True
    else:
        return False

conversations["vader_acc"] = conversations.apply(is_equal, axis=1)

conversations.head(20)

counts = conversations['vader_acc'].value_counts()
print(counts)

conversations.head(10)

conversations.shape