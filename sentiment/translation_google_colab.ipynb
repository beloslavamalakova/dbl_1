{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This file has to be run in google colab, otherwise it will not run.**"
      ],
      "metadata": {
        "id": "xn2JOVETgRtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dl-translate"
      ],
      "metadata": {
        "id": "2B4t6RfvoRbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7G-UGnxflX5"
      },
      "outputs": [],
      "source": [
        "import dl_translate as dlt\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import ssl\n",
        "import certifi\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "# Computes sentences separately for faster translating times\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loads model, device auto sets it so the GPU can be used if possible.\n",
        "mt = dlt.TranslationModel(device=\"auto\")\n",
        "mt = dlt.TranslationModel(\"facebook/nllb-200-distilled-600M\", model_family=\"nllb200\")"
      ],
      "metadata": {
        "id": "YI_TZe94fwsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure SSL context to use certifis CA bundle\n",
        "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
        "ssl._create_default_https_context = lambda: ssl_context\n",
        "\n",
        "# Download the vader_lexicon data\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "analyser = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "yxRXItlLjlfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload the klm_conv_translated.csv file from sentiment_analysis_DFs.py below. This should be found in the sentiment folder on git."
      ],
      "metadata": {
        "id": "d9HS7oMzeoGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload the file to be translated here.\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "metadata": {
        "id": "GLOJLqjlh_6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the CSV file\n",
        "df = pd.read_csv('klm_conv_translated.csv')\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "af89MzbXTdMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below adds the translations of every tweet in a new column called \"translation\". The loop also prints the original Dutch text, to confirm it is actually running.\n",
        "\n",
        "This takes about **2-3 hours** to run. Which is within the daily 3h20min running time from the free plan."
      ],
      "metadata": {
        "id": "JvF7HMGYfswW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"translation\"] = [(\" \".join(mt.translate(nltk.tokenize.sent_tokenize(x, \"dutch\"), source=dlt.lang.DUTCH, target=dlt.lang.ENGLISH, batch_size=64)), print(x)) for x in df[\"cleaned_text\"]]"
      ],
      "metadata": {
        "id": "Ehe5ZTgphR1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adds the compound sentiment to a new column\n",
        "df['compound'] = [analyser.polarity_scores(x)['compound'] for x in df['translation']]\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "2rF4Ve0Bj9u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to categorize sentiment based on score\n",
        "def categorize_sentiment(row):\n",
        "    score = row[\"compound\"]\n",
        "\n",
        "    if score > 0.05:\n",
        "        return \"Positive\"\n",
        "    elif score < -0.05:\n",
        "        return \"Negative\"\n",
        "    else:\n",
        "        return \"Neutral\"\n",
        "\n",
        "# Adds the sentiment in the form of a label\n",
        "df['vader_label'] = df.apply(categorize_sentiment, axis=1)\n",
        "\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "nOa-DVgokMz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Overview of pos/neg/neu sentiment percentages\n",
        "positive_count = df['vader_label'].value_counts().get('Positive', 0)\n",
        "negative_count = df['vader_label'].value_counts().get('Negative', 0)\n",
        "neutral_count = df['vader_label'].value_counts().get('Neutral', 0)\n",
        "total_count = df['vader_label'].notna().sum()\n",
        "\n",
        "percentage_positive = (positive_count / total_count) * 100\n",
        "percentage_negative = (negative_count / total_count) * 100\n",
        "percentage_neutral = (neutral_count / total_count) * 100\n",
        "\n",
        "print(percentage_positive)\n",
        "print(percentage_negative)\n",
        "print(percentage_neutral)"
      ],
      "metadata": {
        "id": "1eeOIoF3lMoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloads the resulting dataframe as a csv file.\n",
        "df.to_csv(\"translated_final.csv\")\n",
        "files.download(\"translated_final.csv\")"
      ],
      "metadata": {
        "id": "WhzETlbEhZJY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}