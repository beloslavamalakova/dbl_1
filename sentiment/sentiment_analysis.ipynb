{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Loading libraries, Data frame, VADERS and testing it ",
   "metadata": {
    "collapsed": false
   },
   "id": "8fe4ca0b9692f1bd"
  },
  {
   "cell_type": "code",
   "source": [
    "# maybe ssl and certifi are not needed for you guys but still I will include them\n",
    "\n",
    "import ssl\n",
    "import nltk\n",
    "import certifi\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "3b18f1e34b3bc27e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Loading dataframe (I am using the mock file in this notebook) \n",
    "\n",
    "conversations = pd.read_csv(\"mock_df_conversation.csv\")\n",
    "conversations.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "11980ede56f23e74",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# I had to run the first two lines of code to be able to install VADER, but you may not need them. Just the last two lines\n",
    "\n",
    "# Configure SSL context to use certifis CA bundle\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "ssl._create_default_https_context = lambda: ssl_context\n",
    "\n",
    "# Download the vader_lexicon data\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab1f1887821fecf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Example of how VADER works \n",
    "\n",
    "text1 = \"I love Python!\"\n",
    "\n",
    "text2 = \"I love Python\"\n",
    "\n",
    "scores = analyser.polarity_scores(text1)\n",
    "\n",
    "scores1 = analyser.polarity_scores(text2)\n",
    "\n",
    "print(scores)\n",
    "print(scores1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cafdf08d3d436630"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# No need to run because it does not work\n",
    "# WORD CLOUD\n",
    "# I can't make it work for some reason, you can even scratch the code and make the word cloud yourself.\n",
    "\n",
    "# Concatenate all text data into a single string\n",
    "data = \" \".join(conversations['text'])\n",
    "\n",
    "# On Windows, you can use: \"C:\\\\Windows\\\\Fonts\\\\Arial.ttf\"\n",
    "# On macOS, you can use: \"/Library/Fonts/Arial.ttf\"\n",
    "# On Linux, you can use: \"/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf\"\n",
    "font_path = \"/System/Library/Fonts/Supplemental/Arial Unicode.ttf\" # This may need to be changed based on your laptop and os\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(data)\n",
    "\n",
    "# Display the word cloud using matplotlib\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Hide axes\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3ea264480ec6d8a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preprocessing and sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b641fd344953f7fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Don't run this is just a suggestion for now\n",
    "# I don't know if we should do this\n",
    "# Iterating over each row in the 'text' column and checking if the text starts with a '@' symbol, indicating a mention. If a mention is found, we are removing the mention by finding the index of the first space character after the '@' symbol and retains the text following that space.\n",
    "\n",
    "conversations['text'] = conversations['text_']\n",
    "\n",
    "for i in range(len(conversations['text'])):\n",
    "    str_val = conversations['text'].iloc[i]\n",
    "    if str_val.startswith(\"@\"):\n",
    "        first_idx = str_val.index(\" \") + 1\n",
    "        conversations.loc[i, 'text'] = str_val[first_idx:]\n",
    "\n",
    "conversations.drop(columns=['text_'], inplace=True)\n",
    "\n",
    "conversations.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f5e29e3bea09b48"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Data Cleaning (only remove URLs)\n",
    "# Overrides the existing column \"cleaned_text\" \n",
    "\n",
    "# Function to clean tweet text without removing special characters\n",
    "def clean_tweet_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "# Apply cleaning function to the text column\n",
    "conversations['cleaned_text'] = conversations['text'].apply(clean_tweet_text)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e1fa1d3b09fa75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sentiment analysis (only on english tweets, other languages get a NaN value)\n",
    "# Creating the 'sentiment_score' column (in integers)\n",
    "\n",
    "# Function to get sentiment score\n",
    "def get_sentiment_score(text, lang):\n",
    "    if lang == 'en':\n",
    "        return analyser.polarity_scores(text)['compound']\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Apply sentiment analysis conditionally based on language\n",
    "conversations['sentiment_score'] = conversations.apply(lambda row: get_sentiment_score(row['cleaned_text'], row['lang']), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "930b35745707495d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creates the \"sentiment\" column (string format) \n",
    "# Other languages have a NaN value\n",
    "\n",
    "# Function to categorize sentiment based on score\n",
    "def categorize_sentiment(score):\n",
    "    if score > 0.05:\n",
    "        return \"Positive\"\n",
    "    elif score < -0.05:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\"\n",
    "\n",
    "# Apply categorization function to the sentiment score column\n",
    "conversations['sentiment'] = conversations['sentiment_score'].apply(categorize_sentiment)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8151b0a5e1b196b2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conversations.head(10)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ea0790136bd5795"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Small exploration of sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "790654a4f5759097"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Visualisation of the amount of tweets per \"sentiment\" \n",
    "# It is not \"accurate\", because the majority of the tweets are automatically neutral if they are not in english\n",
    "\n",
    "# Prepare data for visualization\n",
    "sentiment_counts = conversations['sentiment'].value_counts()\n",
    "\n",
    "# Plot the data\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(sentiment_counts.index, sentiment_counts.values, color=['red', 'green', 'blue'])\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Sentiment Analysis of Tweets')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cbded335b5d654d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Some statistics\n",
    "\n",
    "# Compute the average sentiment score\n",
    "average_sentiment_score = conversations['sentiment_score'].mean()\n",
    "print(f\"Average Sentiment Score: {average_sentiment_score}\")\n",
    "\n",
    "# Count positive and negative scores\n",
    "positive_count = (conversations['sentiment_score'] > 0.05).sum()\n",
    "negative_count = (conversations['sentiment_score'] < -0.05).sum()\n",
    "\n",
    "print(f\"Number of Positive Scores: {positive_count}\")\n",
    "print(f\"Number of Negative Scores: {negative_count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "395823d53baddb8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Maybe a useless plot can be changed when we have the whole dataset\n",
    "\n",
    "# Plot the change in sentiment scores over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(conversations['created_at_datetime'], conversations['sentiment_score'], marker='o', linestyle='-', color='b')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.title('Change in Sentiment Score Over Time')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2009a7bd0737d0d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
